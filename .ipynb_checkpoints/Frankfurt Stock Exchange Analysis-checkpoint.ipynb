{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26ab6fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv('NASDAQ_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a48c791",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://data.nasdaq.com/api/v3/datasets/FSE/AFX_X?start_date=2017-01-01&end_date=2017-12-31&api_key=9RTSF1WTEJssTsozKAmM'\n",
    "r = requests.get(url, '9RTSF1WTEJssTsozKAmM')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9f8061",
   "metadata": {},
   "source": [
    "1. Requesting the url from Nasdaq, making sure that the ticker symbol is changed to AFX_X, the start date is Jan.1, 2017 and the end date is Dec. 31, 2017 to get the entire year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecb65420",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02448128",
   "metadata": {},
   "source": [
    "2. This converts the data from a json structure to a dictionary type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61497bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'dataset_code', 'database_code', 'name', 'description', 'refreshed_at', 'newest_available_date', 'oldest_available_date', 'column_names', 'frequency', 'type', 'premium', 'limit', 'transform', 'column_index', 'start_date', 'end_date', 'data', 'collapse', 'order', 'database_id'])\n"
     ]
    }
   ],
   "source": [
    "print(json_data['dataset'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baccd3c",
   "metadata": {},
   "source": [
    "We can now see the keys to the dictionary. By looking at the documentation of the API found here: https://data.nasdaq.com/data/FSE-frankfurt-stock-exchange/documentation,\n",
    "we can see that there are 11 columns within the key \"data.\" So, the value corresponding to the key \"data\" is a list, with the second value (index 1) being the value of the stock at the opening of the market on each day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "046623ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "open_list=[]\n",
    "for i in range(len(json_data['dataset']['data'])):\n",
    "    open_list.append(json_data['dataset']['data'][i][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1949bc23",
   "metadata": {},
   "source": [
    "This loop generates a list of all values that are opening values of the stock we are looking at. The opening value is the 2nd element in each list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5d02cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_open_list=list(filter(lambda item: item is not None, open_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f79dd50",
   "metadata": {},
   "source": [
    "There are a few values that are \"None\" in this list, so we need to remove those before doing anything numeric with this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d091923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.11 34.0\n"
     ]
    }
   ],
   "source": [
    "print(max(new_open_list),min(new_open_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cc0c1e",
   "metadata": {},
   "source": [
    "3. As seen above, the maximum opening data stock price in 2017 for Carl Zeiss Meditec was 53.11 while the lowest opening day price was Carl Zeiss Meditec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54b2dff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-05-11 2.8100000000000023\n"
     ]
    }
   ],
   "source": [
    "high_low_list=[]\n",
    "for i in range(len(json_data['dataset']['data'])):\n",
    "    high_low_list.append(json_data['dataset']['data'][i][2]-json_data['dataset']['data'][i][3])\n",
    "for i in range(len(json_data['dataset']['data'])):\n",
    "    if (json_data['dataset']['data'][i][2]-json_data['dataset']['data'][i][3]==max(high_low_list)):\n",
    "        print(json_data['dataset']['data'][i][0],max(high_low_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed247d94",
   "metadata": {},
   "source": [
    "4. To calculate the largest change in stock price during the course of a day, we subtract the lowest value for each day from the highest value for each day and store these values in a list. We then calculate the maximum in the list to find the most volatility in one day. After finding this value, we then find the date associated so we have both the most volatile day and the amount of volatility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64e6f02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "closing_change_list=[]\n",
    "for i in range(len(json_data['dataset']['data'])-1):\n",
    "    closing_change_list.append(json_data['dataset']['data'][i+1][4]-json_data['dataset']['data'][i][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96255775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-08 2017-08-09 2.559999999999995\n"
     ]
    }
   ],
   "source": [
    "max_change = 0\n",
    "for i in closing_change_list:\n",
    "    if abs(i) > abs(max_change):\n",
    "        max_change = i\n",
    "for i in range(len(json_data['dataset']['data'])-1):\n",
    "    if (json_data['dataset']['data'][i+1][4]-json_data['dataset']['data'][i][4]) == max_change:\n",
    "        print(json_data['dataset']['data'][i+1][0],json_data['dataset']['data'][i][0], max_change)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e31996",
   "metadata": {},
   "source": [
    "5. To get the largest change between any two days, we subtract the closing stock price of each pair of consecutive days. We subtract the day i from day i+1 because the days run from last to first in our dictionary. We put all of these into a list, then iterate through the list, taking the absolute value in case the largest change is a negative value. Then, we again iterate through our data to find the dates where this greatest change occurred. The largest change was 2.56 points from 8/8/17 to 8/9/17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88c1b06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89124.33725490196\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "for i in range(len(json_data['dataset']['data'])):\n",
    "    total+= json_data['dataset']['data'][i][6]\n",
    "    ave_trade_volume = total/(len(json_data['dataset']['data']))\n",
    "print(ave_trade_volume)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19a185e",
   "metadata": {},
   "source": [
    "6. To find the average daily trading volume for the year, we iterate through the 7th value in each dictionary, summing them as we go. Then we divide this total by the total length to the the average, which is 89,123.34."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61c86c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76600.0\n"
     ]
    }
   ],
   "source": [
    "median_list=[]\n",
    "for i in range(len(json_data['dataset']['data'])):\n",
    "    median_list.append(json_data['dataset']['data'][i][6])\n",
    "median_list.sort()\n",
    "list_length = len(median_list)\n",
    "\n",
    "if list_length%2==1:\n",
    "    print(median_list[int((list_length+1)/2)])\n",
    "else:\n",
    "    print((median_list[int((list_length)/2)]+median_list[int(list_length/2)+1])/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1289f5b",
   "metadata": {},
   "source": [
    "7. To find the median trading volume, we again iterate through each day of trading, but this time we add every day trading volume to a list. We then sort the list. Next, we see check to see if the lenght of the list is odd. If it is odd, we can just find the middle number, which is the length of the list + 1, divided by 2. Otherwise, the length of the list is even and we need to take the average of the two middle numbers in the list."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
